#a
# Generate predictor X and noise vector eps
set.seed(123)
X <- rnorm(100)
eps <- rnorm(100)
#b
# Generate response Y according to the model y = Bo + B1X + B2X^2 + B3X^3 + eps
Y <- 1 + 2*X + 3*X^2 + 4*X^3 + eps
# Create data frame containing X and Y
data <- data.frame(X, Y)
#c
# Perform best subset selection using regsubsets
library(leaps)
#d
## Stepwise forward/backward linear regression
regfit.full <- regsubsets(Y ~ poly(X, 10, raw=TRUE), data=data, nvmax=10)
regfit.fwd <- regsubsets(Y ~ poly(X, 10, raw=TRUE), data=data, nvmax=10, method = "forward")
summary(regfit.fwd)
regfit.bwd <- regsubsets(Y ~ poly(X, 10, raw=TRUE), data=data, nvmax=10, method = "backward")
summary(regfit.bwd)
summary(regfit.bwd)
coef(regfit.full, 10)
coef(regfit.fwd, 10)
coef(regfit.bwd, 10)
#d
## Stepwise forward/backward linear regression
regfit.full <- regsubsets(Y ~ poly(X, 3, raw=TRUE), data=data, nvmax=3)
regfit.fwd <- regsubsets(Y ~ poly(X, 10, raw=TRUE), data=data, nvmax=10, method = "forward")
summary(regfit.fwd)
regfit.bwd <- regsubsets(Y ~ poly(X, 10, raw=TRUE), data=data, nvmax=10, method = "backward")
summary(regfit.bwd)
coef(regfit.full, 10)
coef(regfit.fwd, 10)
#d
## Stepwise forward/backward linear regression
regfit.full <- regsubsets(Y ~ poly(X, 3, raw=TRUE), data=data, nvmax=3)
regfit.fwd <- regsubsets(Y ~ poly(X, 10, raw=TRUE), data=data, nvmax=10, method = "forward")
summary(regfit.fwd)
regfit.bwd <- regsubsets(Y ~ poly(X, 10, raw=TRUE), data=data, nvmax=10, method = "backward")
summary(regfit.bwd)
coef(regfit.full, 3)
coef(regfit.fwd, 10)
coef(regfit.bwd, 10)
#e
library(glmnet)
# Generate simulated data
set.seed(123)
n <- 100
X <- matrix(rnorm(n*10), n, 10)
eps <- rnorm(n)
Y <- 1 + 2*X[,1] + 3*X[,2] + 4*X[,3] + eps
grid <- 10^seq(10, -2, length = 100)  # lambda search grid
?glmnet   ## alpha=0 -> ridge; alpha=1 -> lasso
ridge.mod <- glmnet(X, Y, alpha = 0, lambda = grid)
# Fit lasso model using cross-validation
cv.lasso <- cv.glmnet(X, Y, alpha = 0)
plot(cv.lasso)
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
force(College)
View(oldpar)
View(College)
train <- sample(nrow(College), nrow(College)*0.7)
rm(list=ls())                          # Clear environment
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train <- sample(c(TRUE, FALSE), nrow(College), replace = TRUE)
table(train)
test <- !train
# b
lm.fit <- lm(Apps ~ ., data = train)
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train <- sample(c(TRUE, FALSE), nrow(College), replace = TRUE)
table(train)
test <- !train
train <- regsubsets(Salary ~ .,
data = College[train, ], nvmax = 19)
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train <- sample(nrow(College), nrow(College)*0.7)
train_data <- College[train, ]
test_data <- College[-train, ]
train <- sample(c(TRUE, FALSE), nrow(), replace = TRUE)
data(College)
set.seed(123)
train <- sample(nrow(College), nrow(College)*0.7)
train_data <- College[train, ]
test_data <- College[-train, ]
# b
lm.fit <- lm(Apps ~ ., data = train)
train_index <- sample(nrow(College), nrow(College)*0.7)
train <- College[train_index, ]
test <- College[-train_index, ]
# b
lm.fit <- lm(Apps ~ ., data = train)
summary(lm.fit)
lm.pred <- predict(lm.fit, newdata = test)
lm.mse <- mean((test$Apps - lm.pred)^2)
lm.mse
#c
library(glmnet)
x <- model.matrix(Apps ~ ., data = train)
y <- train$Apps
set.seed(123)
cv.ridge <- cv.glmnet(x, y, alpha = 0)
ridge.bestlam <- cv.ridge$lambda.min
ridge.fit <- glmnet(x, y, alpha = 0, lambda = ridge.bestlam)
summary(ridge.fit)
ridge.pred <- predict(ridge.fit, newx = model.matrix(Apps ~ ., data = test))
ridge.mse <- mean((test$Apps - ridge.pred)^2)
ridge.mse
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1)
lasso.bestlam <- cv.lasso$lambda.min
lasso.fit <- glmnet(x, y, alpha = 1, lambda = lasso.bestlam)
summary(lasso.fit)
lasso.pred <- predict(lasso.fit, newx = model.matrix(Apps ~ ., data = test))
lasso.mse <- mean((test$Apps - lasso.pred)^2)
lasso.mse
coef(lasso.fit)
lasso.mse
#e
library(pls)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data=train_data, validation="CV")
pcr_fit <- pcr(Apps ~ ., data=train_data, validation="CV")
pcr_pred <- predict(pcr_fit, newdata=test_data, ncomp=pcr_fit$bestT)
pcr_mse <- mean((test_data$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train_index <- sample(nrow(College), nrow(College)*0.7)
train <- College[train_index, ]
test <- College[-train_index, ]
# b
lm.fit <- lm(Apps ~ ., data = train)
summary(lm.fit)
lm.pred <- predict(lm.fit, newdata = test)
lm.mse <- mean((test$Apps - lm.pred)^2)
lm.mse
#c
library(glmnet)
x <- model.matrix(Apps ~ ., data = train)
y <- train$Apps
set.seed(123)
cv.ridge <- cv.glmnet(x, y, alpha = 0)
ridge.bestlam <- cv.ridge$lambda.min
ridge.fit <- glmnet(x, y, alpha = 0, lambda = ridge.bestlam)
summary(ridge.fit)
ridge.pred <- predict(ridge.fit, newx = model.matrix(Apps ~ ., data = test))
ridge.mse <- mean((test$Apps - ridge.pred)^2)
ridge.mse
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1)
lasso.bestlam <- cv.lasso$lambda.min
lasso.fit <- glmnet(x, y, alpha = 1, lambda = lasso.bestlam)
summary(lasso.fit)
lasso.pred <- predict(lasso.fit, newx = model.matrix(Apps ~ ., data = test))
lasso.mse <- mean((test$Apps - lasso.pred)^2)
lasso.mse
coef(lasso.fit)
#e
library(pls)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data=train, validation="CV")
pcr_pred <- predict(pcr_fit, newdata=test_data, ncomp=pcr_fit$bestT)
pcr_fit <- pcr(Apps ~ ., data=train, validation="CV")
View(pcr_fit)
pcr_pred <- predict(pcr_fit, newdata=test, ncomp=pcr_fit$bestT)
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
pcr.fit <- pcr(Apps ~ ., data = College, scale = TRUE, validation = "CV")  # 10-folds
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
pcr.fit <- pcr(Apps ~ ., data = College, subset = train, scale = TRUE, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred <- predict(pcr.fit, x[test, ], ncomp = 5)
mean((pcr.pred - y.test)^2)
pcr.fit <- pcr(y ~ x, scale = TRUE, ncomp = 5)
summary(pcr.fit)
pcr.fit <- pcr(Apps ~ ., data = College, scale = TRUE, validation = "CV")  # 10-folds
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
pcr.fit <- pcr(Apps ~ ., data = College, subset = train, scale = TRUE, validation = "CV")
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train_index <- sample(nrow(College), nrow(College)*0.7, list = TRUE)
train_index <- sample(nrow(College), nrow(College)*0.7, list = F)
train_index <- sample(nrow(College), nrow(College)*0.7)
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train_index <- sample(nrow(College), nrow(College)*0.7)
train <- College[train_index, ]
test <- College[-train_index, ]
1247233
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train_index <- sample(nrow(College), nrow(College)*0.7)
train <- College[train_index, ]
test <- College[-train_index, ]
# b
lm.fit <- lm(Apps ~ ., data = train)
summary(lm.fit)
lm.pred <- predict(lm.fit, newdata = test)
lm.mse <- mean((test$Apps - lm.pred)^2)
lm.mse
#c
library(glmnet)
x <- model.matrix(Apps ~ ., data = train)
y <- train$Apps
set.seed(123)
cv.ridge <- cv.glmnet(x, y, alpha = 0)
ridge.bestlam <- cv.ridge$lambda.min
ridge.fit <- glmnet(x, y, alpha = 0, lambda = ridge.bestlam)
summary(ridge.fit)
ridge.pred <- predict(ridge.fit, newx = model.matrix(Apps ~ ., data = test))
ridge.mse <- mean((test$Apps - ridge.pred)^2)
ridge.mse
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1)
lasso.bestlam <- cv.lasso$lambda.min
lasso.fit <- glmnet(x, y, alpha = 1, lambda = lasso.bestlam)
summary(lasso.fit)
lasso.pred <- predict(lasso.fit, newx = model.matrix(Apps ~ ., data = test))
lasso.mse <- mean((test$Apps - lasso.pred)^2)
lasso.mse
coef(lasso.fit)
#e
library(pls)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data=train, validation="CV")
pcr_pred <- predict(pcr_fit, newdata=test, ncomp=pcr_fit$bestT)
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
#e
library(pls)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data=train, validation="CV")
summary(pcr.fit)
summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP")
pcr_pred <- predict(pcr_fit, newdata = test, ncomp=pcr_fit$bestT)
validationplot(pcr_fit, val.type = "MSEP")
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
#e
library(pls)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data=train, validation="CV")
summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP")
pcr_pred <- predict(pcr_fit, newdata = test, ncomp=pcr_fit$bestT)
validationplot(pcr_fit, val.type = "MSEP")
pcr.fit <- pcr(y ~ x, scale = TRUE, ncomp = 5)
pcr_fit <- pcr(y ~ x, scale = TRUE, ncomp = 5)
validationplot(pcr_fit, val.type = "MSEP")
pcr_fit <- pcr(y ~ x, scale = TRUE, ncomp = 5)
summary(pcr_fit)
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
summary(pcr_mse)
#e
library(pls)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data=train, validation="CV")
summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP")
pcr_pred <- predict(pcr_fit, newdata = test, ncomp=pcr_fit$bestT)
validationplot(pcr_fit, val.type = "MSEP")
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
summary(pcr_mse)
pcr_mse
pce_M
pcr_M <- pcr_fit$bestT
pcr_mse
pce_M
pcr_M
#f
set.seed(123)
pls_fit <- plsr(Apps ~ ., data = train, validation="CV")
summary(pls.fit)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data = train, validation="CV")
summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP")
pcr_pred <- predict(pcr_fit, newdata = test, ncomp=pcr_fit$bestT)
validationplot(pcr_fit, val.type = "MSEP")
pcr_mse <- mean((pcr.pred - y.test)^2)
pcr_fit <- pcr(Apps ~ ., data = train, validation="CV")
summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP")
pcr_pred <- predict(pcr_fit, newdata = test, ncomp=pcr_fit$bestT)
validationplot(pcr_fit, val.type = "MSEP")
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
pcr_mse
pcr_M
pcr_pred <- predict(pcr_fit, newdata = test, ncomp=5)
validationplot(pcr_fit, val.type = "MSEP")
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_M <- pcr_fit$bestT
pcr_mse
pcr_M
#e
library(pls)
set.seed(123)
pcr_fit <- pcr(Apps ~ ., data = train, validation="CV")
summary(pcr_fit)
validationplot(pcr_fit, val.type = "MSEP")
pcr_pred <- predict(pcr_fit, newdata = test, ncomp=5)
validationplot(pcr_fit, val.type = "MSEP")
pcr_mse <- mean((test$Apps - pcr_pred)^2)
pcr_mse
set.seed(123)
pcr.fit <- pcr(Apps ~ ., data = College, scale = TRUE, validation = "CV")  # 10-folds
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
set.seed(1)
set.seed(123)
pcr.fit <- pcr(Apps ~ ., data = train, scale = TRUE, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred <- predict(pcr.fit, x[test, ], ncomp = 5)
pcr.pred <- predict(pcr.fit, test, ncomp = 5)
mean((pcr.pred - y.test)^2)
mean((test$Apps - pcr_pred)^2)
pcr.fit <- pcr(y ~ x, scale = TRUE, ncomp = 5)
set.seed(123)
pcr.fit <- pcr(Apps ~ ., data = College, scale = TRUE, validation = "CV")  # 10-folds
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
pcr.fit <- pcr(Apps ~ ., data = train, scale = TRUE, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred <- predict(pcr.fit, test, ncomp = 5)
mean((test$Apps - pcr_pred)^2)
#f
set.seed(123)
pls.fit <- plsr(Apps ~ ., data = train, scale = TRUE, validation = "CV")
summary(pls.fit)
validationplot(pls.fit, val.type = "MSEP")
pls.pred <- predict(pls.fit, test, ncomp = 1)
mean((test$Apps - pcr_pred)^2)
pls_fit <- plsr(Apps ~ ., data = train, validation="CV")
summary(pls.fit)
pls_pred <- predict(pls_fit, newdata = test, ncomp=pls_fit$validation$MSEP[,1] == min(pls_fit$validation$MSEP[,1]))
pls_mse <- mean((pls.pred - y.test)^2)
?ncomp
#d
t.test(Boston$medv)
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(MASS)
data(Boston)
library(MASS)
data(Boston)
force(Boston)
# estimate of population mean of medv
mu_hat <- mean(Boston$medv)
# estimate of standard error of mu_hat
se_mu_hat <- sd(Boston$medv)/sqrt(length(Boston$medv))
#(c)
set.seed(123)
B <- 1000 # number of bootstrap samples
boot_means <- numeric(B)
n <- length(Boston$medv)
for(i in 1:B) {
boot_sample <- sample(Boston$medv, n, replace = TRUE)
boot_means[i] <- mean(boot_sample)
}
se_mu_hat_boot <- sd(boot_means)
se_mu_hat_boot
#(d)
mu_hat_lower <- mu_hat - 2 * se_mu_hat_boot
mu_hat_upper <- mu_hat + 2 * se_mu_hat_boot
c(mu_hat_lower, mu_hat_upper)
#Comparing with t.test results
t.test(Boston$medv)$conf.int
#Comparing with t.test results
t.test(Boston$medv)$conf.int
#(e)
mu_hat_med <- median(Boston$medv)
mu_hat_med
#(f)
set.seed(123)
boot_medians <- numeric(B)
for(i in 1:B) {
boot_sample <- sample(Boston$medv, n, replace = TRUE)
boot_medians[i] <- median(boot_sample)
}
se_mu_hat_med_boot <- sd(boot_medians)
se_mu_hat_med_boot
#(g)
mu0.1 <- quantile(Boston$medv, 0.1)
mu0.1
#(h)
set.seed(123)
boot_quantiles <- numeric(B)
for(i in 1:B) {
boot_sample <- sample(Boston$medv, n, replace = TRUE)
boot_quantiles[i] <- quantile(boot_sample, 0.1)
}
se_mu0.1_boot <- sd(boot_quantiles)
se_mu0.1_boot
rm(list = ls())
library(faraway)
data("worldcup")
str(worldcup)
class(worldcup$Position)
unique(worldcup$Position)
worldcup_no_goalie <- subset(
worldcup,
Position == "Forward"
)
unique(worldcup_no_goalie$Position)
worldcup_no_goalie$Time <- worldcup_no_goalie$Time + 1
worldcup_no_goalie$Passes <- worldcup_no_goalie$Passes + 1
worldcup_no_goalie$Shots <- worldcup_no_goalie$Shots + 1
worldcup_no_goalie$Time <- log(worldcup_no_goalie$Time)
worldcup_no_goalie$Passes <- log(worldcup_no_goalie$Passes)
worldcup_no_goalie$Shots <- log(worldcup_no_goalie$Shots)
set.seed(1)
boot_sims <- 100
boot_output <- c()
for (i in 1:boot_sims) {
# create boot data
boot_data <- worldcup_no_goalie[sample(nrow(worldcup_no_goalie), nrow(worldcup_no_goalie), replace = T), ]
# run a linear model on Shots with Time and Passes as independent variables using boot data
boot_model <- lm(Shots ~ Time + Passes, data = boot_data)
# predicted values
predicted_values <- predict(boot_model, newdata = worldcup_no_goalie)
# find the maximum miss for updated data Shots minus the predicted values
boot_output[i] <- max(abs(worldcup_no_goalie$Shots - predicted_values))
}
summary(round(boot_output, 2))
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
#a
library(caret)
data(College)
set.seed(123)
train_index <- sample(nrow(College), nrow(College)*0.7)
train <- College[train_index, ]
test <- College[-train_index, ]
# b
lm.fit <- lm(Apps ~ ., data = train)
summary(lm.fit)
lm.pred <- predict(lm.fit, newdata = test)
lm.mse <- mean((test$Apps - lm.pred)^2)
lm.mse
View(College)
