n <- length(items)
sdev <- sd(y[items])
output <- rbind (output, c(xbar, ybar, n, x.range, 2*sdev/sqrt(n)))
}
colnames (output) <- c ("xbar", "ybar", "n", "x.lo", "x.hi", "2se")
return (list (binned=output, xbreaks=xbreaks))
}
View(binned.resids)
View(binned.resids)
?predict
?summarise
# Summarize data
mtcars %>%
group_by(cyl) %>%
summarise(mean_mpg = mean(mpg),
mean_hp = mean(hp),
mean_wt = mean(wt)
) %>%
ggplot(., aes(x = cyl, y = mean_mpg)) +
geom_col() +
labs(title = "Mean MPG by Cylinder Count",
x = "Cylinders",
y = "Mean Miles per Gallon")
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(TexMix)
library(sp)
library(ggplot2)
library(maptools)
library(spdep)
library(foreign)
library(e1071)
library(VIM)
library(ClustGeo)
setwd("/Users/jimpan/Documents/EPPS 6326/lab/lab5/TXCnty2021")
TXCnty2021 <- read.dbf("TXCnty2021.DBF")
TXCnty2021.SHP <- readShapePoly("TXCnty2021.SHP", proj4string=CRS("+proj=longlat"))
# Select metric features for potential differences between putative regions
features <- c("LANDAREA", "WATERAREA", "DISTMEX", "LONG", "LAT")
# Subset the TXCnty2021 data frame to include only the selected features
TXCnty2021 <- TXCnty2021[,features]
# Check for redundant features
cor(TXCnty2021)
# Standardize the features if necessary
TXCnty2021 <- scale(TXCnty2021)
TXCnty2021
#Q2 Selection of Spatial Relationships
library(rgdal)
library(spdep)
# Read shapefile
county.shp <- readOGR(dsn = ".", layer = "TXCnty2021")
# Get spatial structure distance matrices
nb <- poly2nb(county.shp, queen=F)
B <- nb2mat(nb, style="B")
topoDist <- 1-B
diag(topoDist) <- 0
topoDist <- as.dist(topoDist)
# Generate distance matrices
topoDist <- dnearneigh(coordinates(county.shp), d1=0, d2=50000, row.names=county.shp$NAME)
sphDist <- dnearneigh(coordinates(county.shp), d1=0, d2=Inf, row.names=county.shp$NAME, longlat=TRUE)
graphDist <- nb2listw(nb, style="W")
topoDist
sphDist
graphDist
# Perform Iterative Cluster Identification
xVars <- TXCnty2021
xVars <- kNN(xVars, k = 5)
summary(xVars$LANDAREA)
row.names(xVars) <- 1:nrow(xVars)
featDist <- dist(scale(xVars))
# Convert featDist to class dist
featDist <- as.dist(featDist)
str(topoDist)
# Convert topoDist to a matrix
topoMat <- as.matrix(topoDist)
# Convert topoMat to a matrix
topoMat <- do.call(rbind, topoMat)
# Convert topoMat to a distance object
topoDist <- as.dist(topoMat)
dim(topoDist)
dim(topoMat)
# Convert topoMat to a matrix
topoMat <- as.matrix(topoDist)
# Transpose topoMat
topoMat <- t(topoMat)
# Convert topoMat to a matrix
topoMat <- do.call(rbind, topoMat)
dim(topoMat)
# Convert topoMat to a matrix
topoMat <- do.call(rbind, topoMat)
# Convert topoMat to a distance object
topoDist <- as.dist(topoMat)
topoDist <- as.dist(topoDist)
# Evaluate mixture of feature and spatial dissimilarity.
K <- 12
range.alpha <- seq(0, 1, by = 0.1)
cr <- choicealpha(featDist, topoDist, range.alpha, K, graph = TRUE)
alpha <- cr$alpha
tree <- hclustgeo(featDist, geoDist, alpha = alpha)
tree <- hclustgeo(featDist, topoDist, alpha = alpha)
plot(tree, hang = -1)
tree <- hclustgeo(featDist, topoDist, alpha = alpha)
tree <- hclustgeo(featDist, topoDist, alpha = 0.2)
plot(tree, hang = -1)
rect.hclust(tree, k = K)
# Number of census tracts per market area
neighClus <- as.factor(cutree(tree, K))
table(neighClus)
# Map Results
mapColorQual(neighClus, county.shp,
map.title = "Spatially Constrained Cluster Analysis",
legend.title = "Cluster\nId.", legend.cex = 0.9)
plot(lakesShp, col = "skyblue", border = "skyblue", add = TRUE)
plot(hwyShp, col = "cornsilk2", lwd = 4, add = TRUE)
plotBoxesByFactor(xVars, neighClus, ncol = 2, zTrans = TRUE, varwidth = FALSE)
# k=6
# Evaluate mixture of feature and spatial dissimilarity.
K <- 6
range.alpha <- seq(0, 1, by = 0.1)
cr <- choicealpha(featDist, topoDist, range.alpha, K, graph = TRUE)
# Perform spatially constrained cluster analysis
tree <- hclustgeo(featDist, topoDist, alpha = 0.2)
plot(tree, hang = -1)
rect.hclust(tree, k = K)
# Number of census tracts per market area
neighClus <- as.factor(cutree(tree, K))
table(neighClus)
# Map Results
mapColorQual(neighClus, county.shp,
map.title = "Spatially Constrained Cluster Analysis",
legend.title = "Cluster\nId.", legend.cex = 0.9)
plot(lakesShp, col = "skyblue", border = "skyblue", add = TRUE)
plot(hwyShp, col = "cornsilk2", lwd = 4, add = TRUE)
plotBoxesByFactor(xVars, neighClus, ncol = 2, zTrans = TRUE, varwidth = FALSE)
TXCnty2021
##
## Read Poly Shapefiles (readShapePoly in library maptools)
##
getinfo.shape("TXCnty2021.shp")
## Get polygons of neighboring States for geographic frame
## Use only for final maps because of slow drawing
neig.shp <- rgdal::readOGR(dsn=getwd(), layer = "TXNeighbors",
integer64 = "allow.loss", stringsAsFactors=T)
View(neig.shp)
library(tidyverse)
# 1. Install and load the R package: faraway.
# -faraway is an R package that provides statistics on the World Cup.
#install.packages("faraway")
library(faraway)
# 2. Download data from faraway using data(worldcup)
data(worldcup)
# 3. Use these functions to assess the data:
# -head to view the first six observations.
# -str to summarize the data and variable type.
# -summary to get summary statistics of the data.
head(worldcup)
str(worldcup)
summary(worldcup)
# 3. Write a linear model for the relationship of Passes on the number of Shots.
# -(Hint) I used dummy code for this last class.
pass_shot_mod <- lm(data = worldcup, Shots ~ Passes)
# 4. What is the effect of Passes on the number of Shots? What is the standard error of Passes on Shots?
summary(pass_shot_mod)
# 5. Add in an additional variable, Time, to the linear model.
time_mod <- lm(data = worldcup, Shots ~ Passes + Time)
# 6. How did the estimated effect of Passes change when Time is added as a control variable? What does this suggest about the relationship between Passes, Time, and Shots? Which of the effects are statistically significant at the 0.05 level?
summary(time_mod)
# 7. Create a table from the two models you made and export that to Latex for analysis.
library(stargazer)
stargazer(pass_shot_mod,
type = "latex",
title = "Linear Model of Passes on the Number of Shots.", header = FALSE)
stargazer(time_mod,
type = "latex",
title = "Linear Model of Passes on the Number of Shots and Time", header = FALSE)
# 9. Using the ggplot2 code from last class that I demoed, plot the relationship between time and shots as scatter plot with a linear relationship. Is the relationship positively or negatively correlated? Is the relationship linear?
#   (Best "looking" data visualization will get extra credit)
ggplot(worldcup, aes(x = Time, y = Shots)) + geom_point() + geom_smooth(method = "lm")
## Download
data(mtcars)
## Scaling the variables so they have a mean of zero and standard deviation of one.
mtcars$mpg <- as.numeric(scale(mtcars$mpg))
mtcars$hp  <- as.numeric(scale(mtcars$hp))
mtcars$wt  <- as.numeric(scale(mtcars$wt))
## Fitting a logistic regression
model <- glm(am ~ mpg + hp + wt, data = mtcars, family = "binomial")
## Summarizing the model
summary(model)
## Creating a fake data.frame
pred_data <- data.frame(
mpg = c(0, 1),
hp = 0,
wt = 0
)
## Predict values
pred_values <- predict(model, ## The model we fit
newdata = pred_data, # the fake code we created
type = "response" ## Pred probs
)
## Look at differences
round(
pred_values[2] - # When mpg = 1
pred_values[1], # When mpg = 0
2) # Rouding to the nearest thousand
## Redoing it with setting hp and wt to 1
pred_data <- data.frame(
mpg = c(0, 1),
hp = 1,
wt = 1
)
## Predict values
pred_values <- predict(model, ## The model we fit
newdata = pred_data, # the fake code we created
type = "response" ## Pred probs
)
## Look at differences
round(
pred_values[2] - # When mpg = 1
pred_values[1], # When mpg = 0
2) # Rouding to the nearest thousand
library(faraway)
data("pulp")
force(pulp)
modelpulp <- lm(Brightness ~ Operator, data = pulp)
modelpulp <- lm(bright ~ operator, data = pulp)
summary(modelpulp)
predict(lm1, data.frame(operator = "b"), interval = "prediction", level = 0.95)
predict(lm1, data.frame(operator = "operatorb"), interval = "prediction", level = 0.95)
predict(modelpulp, data.frame(operator = "operatorb"), interval = "prediction", level = 0.95)
predict(pulp, data.frame(operator = "operatorb"), interval = "prediction", level = 0.95)
library(faraway)
data("pulp")
modelpulp <- lm(bright ~ operator, data = pulp)
summary(modelpulp)
# Predictions for operator B with 95% prediction interval
predict(modelpulp, newdata = data.frame(operator = "b"), interval = "prediction", level = 0.95)
data("nes96")
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(faraway)
data("nes96")
data("hsb")
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(faraway)
data("hsb")
force(hsb)
View(hsb)
data("nes96")
force(nes96)
View(nes96)
data(nes96)
data(nes96)
force(nes96)
View(nes96)
library(nnet)
View(nes96)
sprogram <- hsb$prog
sprog <- hsb$prog
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(faraway)
data("hsb")
sprog <- hsb$prog
model <- multinom(prog ~ gender + race + ses + school + read + write + math + science + social, data = hsb)
mmode <- multinom(prog ~ ., data = hsb)
#a
mmod <- multinom(prog ~ ., data = hsb)
#b
mmodi- step(mmode)
#b
mmodi- step(mmod)
#b
mmodi <-  step(mmod)
?hsb
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(faraway)
data("hsb")
?hsb
library(nnet)
#a
mmod <- multinom(prog ~ ., data = hsb)
#b
mmodi <-  step(mmod)
summary(mmod)
summary(mmodi)
#c
mmode <- multinom(formula = prog ~ ses + schtyp + math + science + socst,
data = hsb)
deviance(mmode) - deviance(mmod)
?nes96
?edf
?deviance
?pchisq
pchisq(10.59434, mmod$edf- mmode$edf, lower = F)
source("~/.active-rstudio-document", echo=TRUE)
predict(mmodi, newdata = ,type = "probs")
predict(mmodi, newdata = ,type = "probs")
prmat <- predict(mmodi, newdata = ,type = "probs")
plot(unique(nincome), prmat[,1], type=”l”, col=”blue”, lwd=3,
summary(mmodi)
summary(prmat)
#intercept
cc <-  c(0,-2.587029,-6.687272)
exp(cc)/sum(exp(cc))
#slope
(pp ¡- predict(mmodi,newdata = ,type=”probs”))
#slope
(pp <-  predict(mmodi,newdata = ,type=”probs”))
#slope
pp <-  predict(mmodi,newdata = ,type=”probs”)
#slope
pp <- predict(mmodi,newdata = ,type=”probs”)
#slope
pp <- predict(mmodi,newdata = ,type = "probs")
#slope
(pp <- predict(mmodi,newdata = ,type = "probs"))
log(pp[1,1]*pp[2,2]/(pp[1,2]*pp[2,1]))
log(pp[1,1]*pp[2,3]/(pp[1,3]*pp[2,1]))
# Create a table
library(xtable)
tab <- data.frame(
"Model" = c("Full", "Reduced"),
"Predictors" = c("All", "ses, schtyp, math, science, socst"),
"Deviance" = c(deviance(mmod), deviance(mmode)),
"df" = c(mmod$edf, mmode$edf),
"AIC" = c(AIC(mmod), AIC(mmode))
)
texreg(tab)
# Create a table
library(texreg)
texreg(tab)
tab
# Chi-squared test table
cat("Chi-squared test for model comparison:\n")
(chi2 <- pchisq(deviance(mmode) - deviance(mmod), mmod$edf - mmode$edf, lower = FALSE))
screenreg(data.frame(chi2 = chi2),
custom.coef.names = "Chi-squared",
caption = "Chi-squared test for comparing full and reduced models")
# Create a table
library(xtable)
# create a data frame of predicted probabilities
prmat <- predict(mmodi, newdata = hsb, type = "probs")
# round the probabilities to 2 decimal places
prmat <- round(prmat, 2)
# add row and column names
rownames(prmat) <- c("General", "Academic", "Vocational")
colnames(prmat) <- c("0", "1", "2", "3", "4")
# create the table with xtable
table1 <- xtable(prmat, caption = "Predicted Probabilities for Multinomial Logistic Regression Model",
label = "table1")
# print the table
print(table1, include.rownames = TRUE, caption.placement = "top")
mmodi_summary <- summary(mmodi)
coef_table <- mmodi_summary$coefficients
rownames(coef_table) <- c("Intercept: gen", "Intercept: voc", "ses", "schtyp", "math", "science", "socst")
colnames(coef_table) <- c("Estimate", "Std. Error", "z value", "Pr(>|z|)")
print(xtable(coef_table, caption = "Multinomial logistic regression coefficients for predicting program type", label = "tab:regression-coefs"),
caption.placement = "top",
include.rownames = TRUE,
sanitize.colnames.function = identity,
sanitize.text.function = identity)
# Intercept values
intercept <- exp(coef(mmodi)[,1])
intercept <- intercept/sum(intercept)
# Create table
table_data <- data.frame(Category = levels(hsb$prog),
Intercept = round(intercept, 3),
stringsAsFactors = FALSE)
# Add label for referencing in LaTeX document
colnames(table_data) <- c("Category", "Intercept")
table_data$Category <- factor(table_data$Category, levels = c("vocation", "general", "academic"))
label(table_data) <- "tab:intercepts"
# Print table
print(table_data, row.names = FALSE)
library(xtable)
# model comparison
model_comp <- data.frame(Model = c("mmod", "mmodi", "mmode"),
Deviance = c(deviance(mmod), deviance(mmodi), deviance(mmode)),
df = c(mmod$edf, mmodi$edf, mmode$edf),
pchisq = c(NA, pchisq(deviance(mmode) - deviance(mmod),
mmod$edf - mmode$edf, lower.tail = FALSE), NA))
# table with model comparison
model_comp_table <- xtable(model_comp, caption = "Model Comparison Results", label = "tab:modelcomp")
print(model_comp_table, caption.placement = "top", include.rownames = FALSE)
# intercept and slope
coef_table <- data.frame(Coefficient = c("Intercept", "Slope"),
Value = c(exp(cc[1])/sum(exp(cc)),
log(pp[1,1]*pp[2,2]/(pp[1,2]*pp[2,1]))),
SE = c(NA, log(pp[1,1]*pp[2,3]/(pp[1,3]*pp[2,1]))))
# table with intercept and slope
coef_table <- xtable(coef_table, caption = "Intercept and Slope", label = "tab:coef")
print(coef_table, caption.placement = "top", include.rownames = FALSE)
# predict values
prmat <- predict(mmodi, newdata = hsb, type = "probs")
predict_table <- data.frame(hsb$prog, prmat)
colnames(predict_table)[1] <- "prog"
predict_table <- xtable(predict_table, caption = "Predicted Values", label = "tab:predict")
print(predict_table, caption.placement = "top", include.rownames = FALSE)
#c
mmode <- multinom(formula = prog ~ ses + schtyp + math + science + socst,
data = hsb)
dev_diff <- deviance(mmode) - deviance(mmod)
pval <- pchisq(dev_diff, mmod$edf - mmode$edf, lower = F)
# Table 1: Model summary
tab1 <- xtable(summary(mmod))
# Add table caption and label
attr(tab1, "caption") <- "Model summary of the multinomial regression"
attr(tab1, "label") <- "tab:model-summary"
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(faraway)
data("hsb")
?hsb
library(nnet)
#a
mmod <- multinom(prog ~ ., data = hsb)
#b
mmodi <-  step(mmod)
#c
mmode <- multinom(formula = prog ~ ses + schtyp + math + science + socst,
data = hsb)
#predict values
prmat <- predict(mmodi, newdata = ,type = "probs")
summary(mmod)
summary(mmodi)
summary(prmat)
# table with model comparison
model_comp_table <- xtable(model_comp, caption = "Model Comparison Results", label = "tab:modelcomp")
print(model_comp_table, caption.placement = "top", include.rownames = FALSE)
rm(list=ls())                          # Clear environment
oldpar <- par()                        # save default graphical parameters
if (!is.null(dev.list()["RStudioGD"])) # Clear plot window
dev.off(dev.list()["RStudioGD"])
cat("\014")                            # Clear the Console
library(faraway)
data("hsb")
?hsb
library(nnet)
#a
mmod <- multinom(prog ~ ., data = hsb)
summary(mmod)
#b
mmodi <-  step(mmod)
summary(mmodi)
#c
mmode <- multinom(formula = prog ~ ses + schtyp + math + science + socst,
data = hsb)
deviance(mmode) - deviance(mmod)
pchisq(10.59434, mmod$edf- mmode$edf, lower = F)
#predict values
prmat <- predict(mmodi, newdata = ,type = "probs")
summary(prmat)
#intercept
cc <-  c(0,-2.587029,-6.687272)
exp(cc)/sum(exp(cc))
#slope
(pp <- predict(mmodi,newdata = ,type = "probs"))
log(pp[1,1]*pp[2,2]/(pp[1,2]*pp[2,1]))
log(pp[1,1]*pp[2,3]/(pp[1,3]*pp[2,1]))
library(xtable)
# model comparison
model_comp <- data.frame(Model = c("mmod", "mmodi", "mmode"),
Deviance = c(deviance(mmod), deviance(mmodi), deviance(mmode)),
df = c(mmod$edf, mmodi$edf, mmode$edf),
pchisq = c(NA, pchisq(deviance(mmode) - deviance(mmod),
mmod$edf - mmode$edf, lower.tail = FALSE), NA))
# table with model comparison
model_comp_table <- xtable(model_comp, caption = "Model Comparison Results", label = "tab:modelcomp")
print(model_comp_table, caption.placement = "top", include.rownames = FALSE)
# intercept and slope
coef_table <- data.frame(Coefficient = c("Intercept", "Slope"),
Value = c(exp(cc[1])/sum(exp(cc)),
log(pp[1,1]*pp[2,2]/(pp[1,2]*pp[2,1]))),
SE = c(NA, log(pp[1,1]*pp[2,3]/(pp[1,3]*pp[2,1]))))
# table with intercept and slope
coef_table <- xtable(coef_table, caption = "Intercept and Slope", label = "tab:coef")
print(coef_table, caption.placement = "top", include.rownames = FALSE)
# predict values
prmat <- predict(mmodi, newdata = hsb, type = "probs")
predict_table <- data.frame(hsb$prog, prmat)
colnames(predict_table)[1] <- "prog"
predict_table <- xtable(predict_table, caption = "Predicted Values", label = "tab:predict")
print(predict_table, caption.placement = "top", include.rownames = FALSE)
# predict values
prmat <- predict(mmodi, newdata = hsb, type = "probs")
predict_table <- data.frame(hsb$prog, prmat)
colnames(predict_table)[1] <- "prog"
# show only the top 10 rows
predict_table_top10 <- head(predict_table, n = 10)
# print the table
predict_table_top10 <- xtable(predict_table_top10, caption = "Predicted Values (Top 10)", label = "tab:predict")
print(predict_table_top10, caption.placement = "top", include.rownames = FALSE)
